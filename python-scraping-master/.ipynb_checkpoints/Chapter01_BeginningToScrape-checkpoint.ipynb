{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'<html>\\n<head>\\n<title>A Useful Page</title>\\n</head>\\n<body>\\n<h1>An Interesting Title</h1>\\n<div>\\nLorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.\\n</div>\\n</body>\\n</html>\\n'\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "html = urlopen('http://pythonscraping.com/pages/page1.html')\n",
    "print(html.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup # 파싱(구문분석. 내가 원하는 정보만 취함)을 원활하게 해줌. \n",
    "\n",
    "html = urlopen('http://www.pythonscraping.com/pages/page1.html')\n",
    "bs = BeautifulSoup(html.read(), 'html.parser') # html.read(), 즉 이 url의 html코드에서 파싱할 수 있게 해주는 객체. \n",
    "print(bs.h1) # 이 url의 코드에서 h1 태그만 출력. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The server could not be found!\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError\n",
    "\n",
    "try:\n",
    "    html = urlopen(\"https://pythonscrapingthisurldoesnotexist.com\") # 정상적이지 않은 url이기 때문에 \n",
    "except HTTPError as e: # 서버까지는 똑바로 접근했지만, 페이지가 없는 경우\n",
    "    print(\"The server returned an HTTP error\")\n",
    "except URLError as e: # 서버 자체가 잘못된 경우 (현재 이 상황!)\n",
    "    print(\"The server could not be found!\")\n",
    "else: # 위의 두 가지 에러 모두 발생하지 않은 경우\n",
    "    print(html.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<h1>An Interesting Title</h1>\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from urllib.error import HTTPError\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "def getTitle(url): # 해당 url에서 title을 가져오는 함수\n",
    "    try: \n",
    "        html = urlopen(url) # url 열어서 해당 페이지 html 가져옴\n",
    "    except HTTPError as e: # 서버까지는 똑바로 접근했지만, 페이지가 없는 HTTPError 발생하면!\n",
    "        print(e)\n",
    "        return None\n",
    "    try:\n",
    "        bsObj = BeautifulSoup(html.read(), \"lxml\") # 이 html 소스 코드를 파싱하기 쉽게 하는 BeautifulSoup 객체 만듦.\n",
    "        '''\n",
    "        BeautifulSoup(html,'html.parser') 로 해도 됨. \n",
    "        lxml 모듈은 선택사항이다. bs4 모듈에 html parser는 내장되어있지만, lxml 의 속도가 더 빠르다. \n",
    "        '''\n",
    "        title = bsObj.body.h1 # BeautifulSoup 객체가 html에서 body 태그 안의 h1 태그를 받아옴. \n",
    "        '''\n",
    "        title1 = bsObj.body.h2 # 에러X. h2태그는 없음. 그냥 title1에는 None 들어가고 잘 실행됨. \n",
    "        title2 = title1.h1     # 에러O. title1=None이 들어가 있으므로 AttributeError 발생!\n",
    "                                        => 이 코드는 수행 안 되고 except문으로 빠짐. \n",
    "                                        'NoneType' object has no attribute 'h1'\n",
    "                                        Title could not be found\n",
    "                               # 보통 이런 식으로 태그 안의 또 다른 태그에 접근하기 때문에 AttributeError 엄청 多多多!!\n",
    "        '''\n",
    "    except AttributeError as e: # 속성 오류 : 속성 이름 잘못됐거나, 없는 속성 가져오려 할 때 발생. \n",
    "        print(e)\n",
    "        return None\n",
    "    return title # except문(None 리턴하고 함수 종료되었음)으로 한 번도 빠지지 않은 경우, 여기서 title 리턴하게 됨. \n",
    "\n",
    "\n",
    "title = getTitle(\"http://www.pythonscraping.com/pages/page1.html\") \n",
    "if title == None:\n",
    "    print(\"Title could not be found\")\n",
    "else:\n",
    "    print(title) # 이 코드에서는 다 잘 작동해서 제대로 print. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
