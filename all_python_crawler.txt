■■■■■■■■■■■■■0617 수업中 새로 알게된것■■■■■■■■■■■■■

     <!-- 
     id:하나의 id는 하나만 가리킴. class:여러 개 소속될수 있음.
     id는 #id{ }, class는 .class{ } 
     
     p.p-target : p라는 태그에서 p-target속성은 이렇게 디자인 해주세요~ 
     li.li-target : li라는 태그에서 li-target속성은 이렇게 디자인 해주세요~ 
     list-style-type: none; : 리스트 표시하는 앞의 표기 없애주세요~
     -->
    <!-- 
    한 칸 띄우면 '자식' !!
    
    div#container p : div라는 태그 중 id가 container인 애들의 '자식' 중에서 p태그 
    div#container div#wrap1 h3 : div라는 태그 중 id가 container인 애들의 '자식' 중에서 div태그 중 id가 wrap1인 애들의 '자식' 중에서 h3태그. 
    -->

■■■■■■■■■■■■■0618 수업中 새로 알게된것■■■■■■■■■■■■■

import requests as rq

url = "https://github.com/kjeon0901"

test = rq.get(url) # rq가 url에 get메시지를 보냄. 
                   # chrome, explorer 등 웹 브라우저를 거치지 않고 url이라는 서버에 접근해서 url웹페이지에 대한 코드를 가져옴. 
'''
파이썬에서는 그냥 rq가 url에 get메시지를 보낸 것 하나지만, 
서버에서는 해당 url에 대한 코드 html, css, javascript 등등을 보내주고, 그걸 실행함으로써 알아서 웹페이지가 열렸다. 

이제는 받아온 데이터 test에서 원하는 정보를 추출할 것임 !!
'''

res = rq.get(url)
print(res)
print(res.status_code)
'''
<Response [200]>
200


내가 어떤 요청을 하고 그게 수행되면 연산 결과 or 상태메시지에 대한 '응답 코드'가 온다. 
<Response [200]>    - 정상적으로 작동했다. 
                    - ex_ 로그인할 때 id, password를 입력하고 로그인 버튼 누르면, id, password를 담은 메시지가 request로 가고, 회원정보에 해당되면 200 반환
<Response [201]>    - 정상적으로 저장되었다. 
<Response [401]>    - 권한이 없다. 
... 수많은 응답 코드가 있으므로 외우지 말고 그때그때 찾아보자!

=> 웹크롤링 하는 도중 문제 해결이 필요하다면 웹에 대한 이런 기본 지식이 필요하다. 
'''

print(res.encoding) # utf-8형식으로 인코딩돼있구나~ 그럼 똑같이 utf-8로 디코딩해야겠구나~
'''utf-8'''

print(res.text) # 리턴받은 html 코드를 console창에 띄워줌. 
'''
......
 1.75h8.5A1.75 1.75 0 0014 13.25v-9.5a1.75 1.75 0 00-.874-1.515.75.75 0 10-.752 1.298.25.25 0 01.126.217v9.5a.25.25 0 01-.25.25h-8.5a.25.25 0 01-.25-.25v-9.5a.25.25 0 01.126-.217z"></path>
</svg>
      <svg aria-hidden="true" viewBox="0 0 16 16" version="1.1" data-view-component="true" height="16" width="16" class="octicon octicon-check js-clipboard-check-icon color-text-success d-none m-2">
    <path fill-rule="evenodd" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path>
</svg>
    </clipboard-copy>
  </div>
</template>


  </body>
</html>
'''

cookies = list(res.cookies)
headers_cookies = res.headers['Set-Cookie']

print('cookies 속성')
print(cookies)
print('')
print('headers 속성')
print(headers_cookies)



res1 = rq.get(url, params={"key1": "value1", "key2": "value2"}) # query string 

print(res1.url)
'''
https://github.com/kjeon0901/?key1=value1&key2=value2

일반적으로 get 명령어에서는 파라미터 설정값을 url주소에다가 한꺼번에 붙여서 넘겨주는 방식 多 사용. 
- 딕셔너리 형태. 

어떤 설정값을 주느냐에 따라 웹페이지 정보가 바뀜. 

네이버 로그인
https://nid.naver.com/nidlogin.login?mode=form&url=https%3A%2F%2Fwww.naver.com
mode    form
url     https%3A%2F%2Fwww.naver.com

네이버 일회용 번호 로그인
https://nid.naver.com/nidlogin.login?mode=number&url=https%3A%2F%2Fwww.naver.com&locale=ko_KR&svctype=1
mode    number
url     https%3A%2F%2Fwww.naver.com
locale  ko_KR
svctype 1

'''

=============================================================

import requests as rq

url1 = "https://aldkfja.com/a" # https://aldkfja.com 라는 서버에서 a라는 웹페이지
res1 = rq.get(url1)
print(res1)
print(res1.status_code)
'''error'''

url2 = "https://github.com/kjeon0901/a" # https://github.com 라는 서버에서 kjeon0901 웹페이지 안의 a라는 웹페이지
res2 = rq.get(url2)
print(res2)
print(res2.status_code)
'''
<Response [404]>
404

서버 : https://github.com/
페이지 : https://github.com/kjeon0901 , https://github.com/kjeon0901/python-spider-machinelearning

url1. 서버 주소 자체를 잘못 입력한 경우 => '사이트에 연결할 수 없음', 코드 상으로는 아예 에러 남. 
url2. 서버에 들어갔는데 페이지가 없는 경우 => 404 뜸. 

프로그램이 돌다가 찾는 페이지 없어서 넘어가면 괜찮지만, 아예 에러가 나서 멈춰 있으면 안되니까 try-catch문 多 써줌! 
'''

def url_check(url):
    res = rq.get(url)

    print(res)

    sc = res.status_code

    if sc == 200:
        print("%s 요청성공"%(url))
    elif sc == 404:
        print("%s 찾을 수 없음" %(url))
    else:
        print("%s 알수 없는 에러 : %s"%(url, sc))


url_check("https://github.com/kjeon0901/")
url_check("https://github.com/kjeon0901//a")
'''
<Response [200]>
https://github.com/kjeon0901/ 요청성공
<Response [404]>
https://github.com/kjeon0901//a 찾을 수 없음
'''

=============================================================

import requests as rq

url = "https://blog.naver.com/kjeon0901"

res = rq.get(url)

print(res)
print(res.headers) # 딕셔너리 타입 
print(len(res.headers))
'''
<Response [200]>
{'Date': 'Fri, 18 Jun 2021 01:06:04 GMT', 'Content-Type': 'text/html;charset=UTF-8', 'Transfer-Encoding': 'chunked', 
 'Connection': 'close', 'Vary': 'Accept-Encoding', 'Cache-Control': 'no-cache', 'Expires': 'Thu, 01 Jan 1970 00:00:00 GMT', 
 'Set-Cookie': 'JSESSIONID=7A8C9A4666E68B5D11A123D946BF986B.jvm1; Path=/; Secure; HttpOnly', 'Content-Encoding': 'gzip', 
 'Server': 'nxfps', 'Referrer-policy': 'unsafe-url'}
11
'''

headers = res.headers
print(headers['Set-Cookie']) # 딕셔너리 타입에 접근할 때에는 key값 이용 !
'''
Cookie
- ex) 내가 어떤 브라우저에서 로그인 한 뒤, 브라우저 껐다가 다시 켰는데 그대로 로그인 되어 있는 경우 '쿠키' 때문!
- '내가 이 브라우저에 접속했다' 는 게 작은 txt파일로 서버가 아니라 내 컴퓨터의 브라우저에 저장되는 것. 
  그러면 내가 브라우저에 다시 접속하면, 브라우저가 그 txt파일을 서버에 보내줘서 로그인 바로바로 되게 해줌. 
- 그런데 보안이 문제! 내 브라우저를 해킹하면 문제! => 조심스럽다. 
'''

for header in headers:
    print(headers[header])
'''
<Response [200]>
Fri, 18 Jun 2021 01:16:38 GMT
text/html;charset=UTF-8
chunked
close
Accept-Encoding
no-cache
Thu, 01 Jan 1970 00:00:00 GMT
JSESSIONID=C62E32687DD25DC10E313A7B5DD396E0.jvm1; Path=/; Secure; HttpOnly
gzip
nxfps
unsafe-url
'''

cookies = res.cookies
print(cookies)
'''
<RequestsCookieJar[<Cookie JSESSIONID=EB17C42065676C826ED5710E0E18AE21.jvm1 for blog.naver.com/>]>
내가 접속한 블로그에 대한 쿠키 파일이 남았다. 
'''

■■■■■■■■■■■■■0619 수업中 새로 알게된것■■■■■■■■■■■■■
■■■■■■■■■■■■■0620 수업中 새로 알게된것■■■■■■■■■■■■■
■■■■■■■■■■■■■0621 수업中 새로 알게된것■■■■■■■■■■■■■